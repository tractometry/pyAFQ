{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Re-running pyAFQ\nSometimes you want to change arguments and re-run pyAFQ. This could be to\ntry different parameters, to run on changed data, or re-run after updating\nparameters due to an error.\n\npyAFQ saves derivatives as it goes, so if you re-run pyAFQ after changing\nparameters, it could use derivatives from previous runs with the\nold parameters.\n\nTo solve this, use the myafq.clobber() or myafq.cmd_outputs() methods. They\nare the same methods. They will delete previous derivatives so you can\nre-run your pipeline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from AFQ.api.group import GroupAFQ\nimport AFQ.data.fetch as afd\nimport os.path as op\nimport os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We start with some example data. The data we will use here is\ngenerated from the\n[Stanford HARDI dataset](https://purl.stanford.edu/ng782rw8378).\nWe then setup our myafq object which we will use to demonstrate\nthe clobber method.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "afd.organize_stanford_data()\n\ntracking_params = dict(n_seeds=100,\n                       random_seeds=True,\n                       rng_seed=2022,\n                       trx=True,\n                       num_chunks=True)\n\nmyafq = GroupAFQ(\n    bids_path=op.join(afd.afq_home, 'stanford_hardi'),\n    preproc_pipeline='vistasoft',\n    tracking_params=tracking_params)\n\n###################\n# Delete Everything\n# -----------------\n# To delete all pyAFQ outputs in the output directory, simply call::\n#\n#     myafq.cmd_outputs()\n#\n# or::\n#\n#     myafq.clobber()\n#\n# This is equivalent to running ``rm -r`` on all pyAFQ outputs. After this,\n# you can re-run your pipeline from scratch.\n#\n# Here, we will delete everything and re-run with a different b0 threshold.\n# The b0_threshold determines which b-values are considered b0.\n# The default is 50.\n\nmyafq.cmd_outputs()\n\nmyafq = GroupAFQ(\n    bids_path=op.join(afd.afq_home, 'stanford_hardi'),\n    preproc_pipeline='vistasoft',\n    b0_threshold=100,\n    tracking_params=tracking_params)\n\nmyafq.export(\"b0\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Delete Some Things\nTo delete only specific types of derivatives while preserving others,\nuse the ``dependent_on`` parameter::\n\n    # Delete only tractography-dependent files\n    myafq.cmd_outputs(dependent_on=\"track\")\n\n    # Delete only bundle recognition-dependent files\n    myafq.cmd_outputs(dependent_on=\"recog\")\n\n    # Delete only profiling-dependent files\n    myafq.cmd_outputs(dependent_on=\"prof\")\n\nYou can also specify exceptions - files to preserve::\n\n    # Delete all outputs except the tractography\n    myafq.cmd_outputs(exceptions=[\"streamlines\"])\n\nHere, we will change the tractography parameters, but we want to keep all\nderivatives not dependent on tractography. Typically, this means keeping\nThe mapping from MNI space and fitted models, but deleting recognized\nbundles and tract profiles.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "myafq.clobber(dependent_on=\"track\")\n\ntracking_params = dict(n_seeds=100,\n                       random_seeds=True,\n                       max_angle=60,\n                       rng_seed=12,\n                       trx=True,\n                       num_chunks=True)\n\nmyafq = GroupAFQ(\n    bids_path=op.join(afd.afq_home, 'stanford_hardi'),\n    preproc_pipeline='vistasoft',\n    b0_threshold=100,\n    tracking_params=tracking_params)\n\nmyafq.export(\"streamlines\")\n\n##################\n# Move Some Things\n# ----------------\n# The ``cmd_outputs`` method is flexible and can perform other file operations\n# besides deletion. For example, to copy files::\n\n#     # Copy only files dependent on tractography\n#     myafq.cmd_outputs(\n#           cmd=\"cp\",\n#           dependent_on=\"track\",\n#           suffix=\"/path/to/backup/\")\n\n# Note: The method automatically adds ``-r``\n#       for \"cp\" and \"rm\" operations.\n\n# Create backup directory\nbackup_dir = op.join(afd.afq_home, \"stanford_hardi_backup\")\nos.makedirs(backup_dir, exist_ok=True)\n\n# Move the outupts of AFQ to this directory\nmyafq.cmd_outputs(cmd=\"mv\", suffix=backup_dir)\n\n##############\n# How It Works\n# ------------\n# The method works by:\n# 1. Identifying all pyAFQ outputs in the output directory\n# 2. Filtering based on the ``dependent_on`` parameter (if provided)\n# 3. Removing any files listed in ``exceptions``\n# 4. Executing the specified command (``rm``, ``mv``, ``cp`` etc.) on the remaining files\n# 5. Resetting the workflow to ensure subsequent runs regenerate affected derivatives\n#\n# We plan to automate this process in the future."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}